# Data Processing 도메인 진로 정리

---

## 1. 도메인 정의 및 핵심 키워드 요약

| 핵심 키워드          | 설명                                             |
| --------------- | ---------------------------------------------- |
| Data Processing | 데이터를 수집하고 가공하여 유의미한 형태로 만드는 작업                 |
| Python + OSS    | Pandas, Airflow, FastAPI 등 오픈소스를 기반으로 한 자동화 처리 |
| Microsoft 환경    | Azure, Power Platform, M365 등과의 연동을 고려해야 함     |
| 도구 조합 전략        | 상황과 조직 환경에 맞는 유연한 도구 선택 능력                     |
| 도메인 적용성         | 개인 프로젝트 vs 기업 실무에 따른 설계 방향 차별화                 |

---

## 2. 도구 선택 전략 – 실무/개인/레거시별 분류표

| 도구 조합                    | 적용 상황           | 특징 요약                    |
| ------------------------ | --------------- | ------------------------ |
| ADF + Synapse + Power BI | Microsoft 내부 업무 | 보안, 연계성, 배포 안정성 높음       |
| Airflow + Pandas + MySQL | 외부 OSS 기반 프로젝트  | 유연성, 코드 기반 제어, 커스터마이징 강점 |
| SSIS + SQL Server        | 온프레미스 기반 조직     | 레거시 호환, 점진적 전환 용이        |
| Pandas + Excel           | 경량 개인 분석        | 빠른 프로토타입, 저비용/저스펙 환경     |
| Snowflake + dbt          | 대기업 분석 플랫폼      | 스케일 확장성, 테이블 관리 자동화      |

* 참고: 설치형 OSS를 직접 배포해보는 경험은 장기적으로 커리어에 큰 자산이 된다. 요즘 대부분의 환경은 PaaS에 의존하지만, 직접 설치 및 운영 능력이 차별점을 만든다.

---

## 3. 선택한 도메인 방향성 요약

| 항목           | 방향성                                          |
| ------------ | -------------------------------------------- |
| 개발 환경        | Linux 기반 배포 + 설치형 OSS 운영                     |
| Python 활용 방식 | 분석용이 아닌 ETL 자동화용으로 활용                        |
| 도구 운용 철학     | PaaS 최소화, 설치형 운영 경험 축적                       |
| 중점 기술 스택     | Airflow, Pandas, FastAPI, MySQL, Docker, Git |
| 장기 목표 기술     | Snowflake, dbt, Spark 등 확장형 플랫폼도 준비          |

* 주피터 노트북은 사용하지 않음 (분석 목적이 아니므로)
* Pandas는 분석이 아닌 경량 데이터 처리용으로 사용
* Microsoft 내부는 ADF, 외부는 Airflow가 주로 활용됨

---

## 4. 실전 실행 전략 – 단계별 로드맵

| 단계  | 목표            | 실습 예시                                       |
| --- | ------------- | ------------------------------------------- |
| 1단계 | 설치형 OSS 배포    | Ubuntu + Docker로 Airflow, MySQL, Grafana 구성 |
| 2단계 | 데이터 수집 자동화    | Public API → 스케줄링 → Pandas 정제               |
| 3단계 | 데이터 저장 및 API화 | MySQL에 저장 후 FastAPI로 REST API 구성            |
| 4단계 | 시각화 연동        | Power BI 또는 Grafana 연동 및 대시보드 구현            |
| 5단계 | 배포 자동화        | GitHub Actions 또는 Airflow 자체로 스케줄링/로깅 구성    |

---

## 5. 자주 받는 질문에 대한 내 답변

| 질문                          | 답변                                                         |
| --------------------------- | ---------------------------------------------------------- |
| 왜 SSIS를 쓰지 않나요?             | MS 내부야 그렇지만, 대부분의 외부 환경에서는 Python + OSS가 더 널리 쓰이며 유연성이 높다. |
| 왜 Jupyter Notebook을 쓰지 않나요? | 분석 목적이 아닌 ETL 자동화를 목표로 하기 때문에 스크립트 중심 개발 환경이 더 적합하다.       |
| 왜 PaaS를 피하나요?               | 설치형 OSS를 직접 설치하며 구조와 설정을 익히는 것이 장기적으로 더 큰 역량이 된다.          |
| 왜 MySQL을 선택했나요?             | Redshift, Snowflake는 비용/복잡도 높음. MySQL은 유연하고 학습/운영 비용이 낮다.  |

---

## 6. 내가 주도할 수 있는 미니 프로젝트 아이디어

| 프로젝트명               | 설명                                                           |
| ------------------- | ------------------------------------------------------------ |
| 공공 API 데이터 수집 자동화   | 지하철, 날씨, 부동산 등 공공 API → Airflow → MySQL 저장 → FastAPI로 API 제공 |
| OSS 기반 데이터 파이프라인 구축 | Airflow 기반으로 데이터 수집, 정제, 저장 및 시각화까지 End-to-End 구성            |
| MS 도구와 OSS 연동 실습    | ADF 수집 → Synapse 저장 → Power BI 시각화 vs Airflow 기반 파이프라인 비교 분석 |

---

## 7. 실행 전략 요약

* GitHub에 실습 기반 프로젝트 기록
* 커밋 메시지, 폴더 구조, README 명확하게 구성
* Docker + Airflow + MySQL + FastAPI 4종 스택 중심 반복 실습
* 설치 및 네트워크 구성 경험 → 문서화 필수
* 블로그에는 기술보다 “왜 이렇게 설계했는가”를 중심으로 글 작성

---

## 최종 정리

나는 단순 분석가가 아닌,
Python + 설치형 OSS 기반의 **실전형 데이터 파이프라인 구축 엔지니어**를 목표로 한다.

외부 OSS와 Microsoft 도구의 장단점을 모두 이해하고,
실제 환경에 유연하게 적용할 수 있는 **양손잡이 데이터 엔지니어**로 성장하고자 한다.

---

필요하시면 이 내용을 Markdown 파일(.md)로 만들어 드리거나, GitHub 블로그용 템플릿에 맞게 커스터마이징해드릴 수도 있어요. 원하시면 바로 도와드릴게요.
